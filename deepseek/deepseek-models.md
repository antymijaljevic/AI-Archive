[Models](https://huggingface.co/deepseek-ai)
[Official repository](https://github.com/deepseek-ai)

# DeepSeek Models (Sorted by Release Date)

 **Model Name**              **Release Date** **Description** 
 DeepSeek Coder              November 2, 2023  First coding-focused model, open-source under MIT                   
 DeepSeek LLM                November 29, 2023 67B-parameter model for general tasks, competitive with GPT-4.                 
 DeepSeek-V2                 May 2024          Affordable model that triggered price competition in Chinaâ€™s AI market.        
 DeepSeek-R1-Lite-Preview    November 2024     Specialized in logical inference and math, outperformed o1 on benchmarks. 
 DeepSeek-VL2                December 13, 2024 Vision-language MoE models for multimodal tasks.
 DeepSeek-V3                 December 26, 2024 671B-parameter MoE model, open-source, trained on 14.8T tokens.

 DeepSeek-R1                 January 20, 2025  Reasoning-focused models; R1-Zero uses RL-only training,
 DeepSeek-R1-Zero                              R1 combines SFT+RL.
 
 DeepSeek-R1-Distill Models January 20, 2025   Smaller distilled versions for efficient reasoning.